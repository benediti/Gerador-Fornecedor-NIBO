import streamlit as st
import pandas as pd
import os
import uuid
from datetime import datetime
from io import BytesIO
import sys

# Adicionar diret√≥rio raiz ao path para imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config_segura import ConfigSegura

# ========================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ========================================
st.set_page_config(
    page_title="NIBO - Processar Dados",
    page_icon="ÔøΩ",
    layout="wide"
)

# ========================================
# FUN√á√ïES AUXILIARES
# ========================================
def gerar_id_unico():
    return str(uuid.uuid4())

def converter_valor_americano(valor):
    if pd.isna(valor):
        return 0.0
    try:
        if isinstance(valor, str):
            valor = valor.replace(',', '.')
        return float(valor)
    except:
        return 0.0

def buscar_stakeholder_id(matricula, df_stakeholders):
    if df_stakeholders is not None and 'matricula' in df_stakeholders.columns:
        try:
            if isinstance(matricula, str):
                matricula = int(matricula.replace('.', '').replace(',', '').replace(' ', ''))
            else:
                matricula = int(matricula)
        except:
            pass
        
        resultado = df_stakeholders[df_stakeholders['matricula'] == matricula]
        if not resultado.empty:
            # A terceira coluna (√≠ndice 2) cont√©m o ID do stakeholder
            if len(df_stakeholders.columns) >= 3:
                return resultado.iloc[0, 2]  # Coluna2 com os IDs
    return None

def buscar_cost_center_id(idsetor, df_cost_centers):
    if df_cost_centers is not None and 'id empresa' in df_cost_centers.columns and 'id cliente' in df_cost_centers.columns:
        resultado = df_cost_centers[df_cost_centers['id empresa'] == idsetor]
        if not resultado.empty:
            return resultado['id cliente'].iloc[0]
    return None

def verificar_ja_processado(df):
    if 'jafoiprocessado' in df.columns:
        processados = df['jafoiprocessado'] == True
        return df, processados.sum()
    else:
        df['jafoiprocessado'] = False
        return df, 0

# ========================================
# INTERFACE PRINCIPAL
# ========================================

st.markdown("""
# üì§ Etapa 1: Processar Planilha
### Transforme sua planilha de benef√≠cios em dados prontos para a API NIBO
---
""")

# ========================================
# SIDEBAR - CONFIGURA√á√ïES
# ========================================
config_segura = ConfigSegura()

with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # API Configuration (opcional nesta etapa)
    with st.expander("üîë API NIBO (Opcional)", expanded=False):
        st.info("üí° A configura√ß√£o da API √© opcional nesta etapa. Ser√° necess√°ria na Etapa 2.")
        
        perfis_salvos = config_segura.listar_perfis()
        
        perfil_selecionado = ""
        if perfis_salvos:
            perfil_selecionado = st.selectbox("Perfil salvo:", [""] + perfis_salvos)
        
        if perfil_selecionado:
            api_url_salva, api_token_salvo = config_segura.carregar_config(perfil_selecionado)
            api_url = api_url_salva or ""
            api_token = api_token_salvo or ""
            st.success(f"‚úÖ Perfil '{perfil_selecionado}' carregado")
        else:
            api_url, api_token = config_segura.carregar_config("default")
            api_url = api_url or ""
            api_token = api_token or ""
        
        api_url_input = st.text_input("URL da API:", value=api_url, placeholder="https://api.nibo.com.br/empresas/v1/")
        api_token_input = st.text_input("Token:", value=api_token, type="password")
        
        col1, col2 = st.columns(2)
        with col1:
            nome_perfil = st.text_input("Nome perfil:", value="default")
        with col2:
            if st.button("ÔøΩ Salvar"):
                if api_url_input and api_token_input and nome_perfil:
                    if config_segura.salvar_config(api_url_input, api_token_input, nome_perfil):
                        st.success("‚úÖ Salvo!")
                        st.rerun()
    
    # Status dos arquivos
    st.header("üìÅ Arquivos de Refer√™ncia")
    arquivos_ref = {
        "FUNC.xlsx": "Funcion√°rios", 
        "centros_de_custo.xlsx": "Centros de Custo", 
        "categorias_nibo.xlsx": "Categorias"
    }
    
    # Diret√≥rio base para procurar os arquivos
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    for arquivo, desc in arquivos_ref.items():
        caminho_arquivo = os.path.join(base_dir, arquivo)
        if os.path.exists(caminho_arquivo):
            st.success(f"‚úÖ {desc}")
        else:
            st.error(f"‚ùå {desc}")

# ========================================
# √ÅREA PRINCIPAL
# ========================================

# Upload de arquivo
st.header("üì§ Upload da Planilha")

# Dica sobre atualiza√ß√£o de arquivo
if 'df_processado' in st.session_state:
    st.info("üí° **Dica:** Se voc√™ editou o arquivo Excel e quer reprocessar, clique em 'üîÑ Limpar Cache' e fa√ßa upload novamente.")

col_upload, col_limpar = st.columns([3, 1])

with col_upload:
    uploaded_file = st.file_uploader(
        "Selecione: Modelo Planilha Imprt Beneficios.xlsx",
        type=['xlsx', 'xls'],
        help="Arquivo deve conter: matricula, idsetor, valor",
        key=f"file_uploader_{datetime.now().strftime('%Y%m%d')}"
    )

with col_limpar:
    st.write("")  # Espa√ßamento
    st.write("")  # Espa√ßamento
    if st.button("üîÑ Limpar Cache", help="Limpa o cache e recarrega os dados"):
        st.cache_data.clear()
        if 'df_processado' in st.session_state:
            del st.session_state['df_processado']
        if 'registros_novos' in st.session_state:
            del st.session_state['registros_novos']
        st.success("‚úÖ Cache limpo! Fa√ßa upload do arquivo novamente.")
        st.rerun()

if uploaded_file is not None:
    try:
        # Mostrar informa√ß√µes do arquivo carregado
        st.info(f"üìÅ **Arquivo:** {uploaded_file.name} | **Tamanho:** {uploaded_file.size / 1024:.1f} KB | **Carregado em:** {datetime.now().strftime('%H:%M:%S')}")
        
        # Ler arquivo com configura√ß√µes mais espec√≠ficas
        df_input = pd.read_excel(uploaded_file, engine='openpyxl')
        
        # Verificar se h√° m√∫ltiplas abas
        if hasattr(uploaded_file, 'name'):
            xls = pd.ExcelFile(uploaded_file)
            if len(xls.sheet_names) > 1:
                st.info(f"üìã Planilha possui {len(xls.sheet_names)} abas: {', '.join(xls.sheet_names)}")
                aba_selecionada = st.selectbox("Selecione a aba:", xls.sheet_names)
                df_input = pd.read_excel(uploaded_file, sheet_name=aba_selecionada, engine='openpyxl')
        
        # Limpar dados iniciais
        df_input = df_input.dropna(how='all')  # Remove linhas completamente vazias
        df_input = df_input.dropna(how='all', axis=1)  # Remove colunas completamente vazias
        
        # Normalizar nomes das colunas
        df_input.columns = df_input.columns.str.lower().str.strip()
        
        st.success(f"‚úÖ Arquivo carregado: {uploaded_file.name}")
        st.info(f"üìä Dados reais encontrados: {len(df_input)} linhas, {len(df_input.columns)} colunas")
        
        # Verificar colunas
        required_columns = ['matricula', 'idsetor', 'valor']
        missing_columns = [col for col in required_columns if col not in df_input.columns]
        
        if missing_columns:
            st.error(f"‚ùå Colunas obrigat√≥rias n√£o encontradas: {missing_columns}")
            st.info("Colunas dispon√≠veis: " + ", ".join(df_input.columns.tolist()))
            st.stop()
        
        # Limpeza autom√°tica inicial dos dados
        registros_originais = len(df_input)
        df_original_backup = df_input.copy()  # Backup para compara√ß√£o
        
        # Rastrear o que foi removido em cada etapa
        indices_removidos_por_etapa = {
            'vazias': set(),
            'obrigatorios': set(),
            'duplicatas': set(),
            'conversao': set(),
            'valores_invalidos': set()
        }
        
        # 1. Remove linhas completamente vazias
        indices_antes = set(df_input.index)
        df_input = df_input.dropna(how='all')
        indices_removidos_por_etapa['vazias'] = indices_antes - set(df_input.index)
        
        # 2. Remove linhas com valores obrigat√≥rios vazios
        indices_antes = set(df_input.index)
        df_input = df_input.dropna(subset=['matricula', 'idsetor', 'valor'])
        indices_removidos_por_etapa['obrigatorios'] = indices_antes - set(df_input.index)
        
        # 3. Remove duplicatas completas (APENAS duplicatas exatas)
        indices_antes = set(df_input.index)
        df_input = df_input.drop_duplicates(subset=['matricula', 'idsetor', 'valor'], keep='first')
        indices_removidos_por_etapa['duplicatas'] = indices_antes - set(df_input.index)
        
        # 4. Converte tipos e corrige formata√ß√£o
        try:
            # Tratar valores primeiro (pode ter v√≠rgula como separador decimal)
            if df_input['valor'].dtype == 'object':
                # Se for texto, trocar v√≠rgula por ponto
                df_input['valor'] = df_input['valor'].astype(str).str.replace(',', '.').str.replace(r'[^\d\.]', '', regex=True)
            df_input['valor'] = pd.to_numeric(df_input['valor'], errors='coerce')
            
            # Tratar matr√≠culas como string primeiro para remover zeros desnecess√°rios
            df_input['matricula'] = df_input['matricula'].astype(str).str.replace(r'\.0$', '', regex=True)
            
            # Converter para inteiro (remove zeros √† direita automaticamente)
            df_input['matricula'] = pd.to_numeric(df_input['matricula'], errors='coerce').astype('Int64')
            df_input['idsetor'] = pd.to_numeric(df_input['idsetor'], errors='coerce').astype('Int64')
            
            # Remove registros onde a convers√£o falhou
            indices_antes = set(df_input.index)
            df_input = df_input.dropna(subset=['matricula', 'idsetor', 'valor'])
            indices_removidos_por_etapa['conversao'] = indices_antes - set(df_input.index)
            
            # Remove valores <= 0
            indices_antes = set(df_input.index)
            df_input = df_input[
                (df_input['matricula'] > 0) & 
                (df_input['idsetor'] > 0) & 
                (df_input['valor'] > 0)
            ]
            indices_removidos_por_etapa['valores_invalidos'] = indices_antes - set(df_input.index)
            
            # Converter matr√≠culas e setores para int normal (sem zeros extras)
            df_input['matricula'] = df_input['matricula'].astype(int)
            df_input['idsetor'] = df_input['idsetor'].astype(int)
            
        except Exception as e:
            st.error(f"‚ùå Erro na convers√£o de tipos: {e}")
            st.stop()
        
        registros_limpos = len(df_input)
        registros_removidos = registros_originais - registros_limpos
        
        if registros_limpos == 0:
            st.error("‚ùå Nenhum registro v√°lido encontrado ap√≥s limpeza!")
            st.stop()
        
        if registros_removidos > 0:
            st.success(f"üßπ Limpeza autom√°tica: {registros_removidos} registros inv√°lidos removidos")
            
            # Mostrar detalhes dos dados removidos
            with st.expander(f"üîç Ver detalhes dos {registros_removidos} registros removidos", expanded=False):
                # Identificar quais registros foram removidos
                indices_mantidos = df_input.index
                df_removidos = df_original_backup[~df_original_backup.index.isin(indices_mantidos)]
                
                if not df_removidos.empty:
                    st.warning(f"**{len(df_removidos)} registros foram removidos durante a limpeza:**")
                    
                    # Categorizar os problemas
                    col1, col2, col3, col4, col5 = st.columns(5)
                    
                    # Contar tipos de problemas usando os √≠ndices rastreados
                    qtd_vazias = len(indices_removidos_por_etapa['vazias'])
                    qtd_obrigatorios = len(indices_removidos_por_etapa['obrigatorios'])
                    qtd_duplicatas = len(indices_removidos_por_etapa['duplicatas'])
                    qtd_conversao = len(indices_removidos_por_etapa['conversao'])
                    qtd_valores_invalidos = len(indices_removidos_por_etapa['valores_invalidos'])
                    
                    with col1:
                        if qtd_vazias > 0:
                            st.metric("üóëÔ∏è Linhas vazias", qtd_vazias)
                    with col2:
                        if qtd_obrigatorios > 0:
                            st.metric("‚ö†Ô∏è Campos vazios", qtd_obrigatorios)
                    with col3:
                        if qtd_duplicatas > 0:
                            st.metric("üîÅ Duplicatas", qtd_duplicatas)
                    with col4:
                        if qtd_conversao > 0:
                            st.metric("‚ùå Erro convers√£o", qtd_conversao)
                    with col5:
                        if qtd_valores_invalidos > 0:
                            st.metric("‚ö™ Valores ‚â§ 0", qtd_valores_invalidos)
                    
                    # Mostrar dados removidos em tabela
                    st.markdown("---")
                    st.markdown("**üìã Registros removidos:**")
                    
                    # Adicionar coluna indicando o motivo
                    df_removidos_display = df_removidos.copy()
                    motivos = []
                    
                    for idx in df_removidos_display.index:
                        linha = df_removidos_display.loc[idx]
                        motivo_lista = []
                        
                        # Verificar qual foi o motivo da remo√ß√£o
                        if idx in indices_removidos_por_etapa['vazias']:
                            motivo_lista.append("Linha vazia")
                        if idx in indices_removidos_por_etapa['obrigatorios']:
                            if pd.isna(linha.get('matricula')):
                                motivo_lista.append("Matr√≠cula vazia")
                            if pd.isna(linha.get('idsetor')):
                                motivo_lista.append("Setor vazio")
                            if pd.isna(linha.get('valor')):
                                motivo_lista.append("Valor vazio")
                        if idx in indices_removidos_por_etapa['duplicatas']:
                            motivo_lista.append("Duplicata")
                        if idx in indices_removidos_por_etapa['conversao']:
                            motivo_lista.append("Erro na convers√£o de tipo")
                        if idx in indices_removidos_por_etapa['valores_invalidos']:
                            motivo_lista.append("Valor ‚â§ 0")
                        
                        motivos.append(", ".join(motivo_lista) if motivo_lista else "Outro")
                    
                    df_removidos_display['Motivo'] = motivos
                    
                    # Mostrar tabela
                    st.dataframe(
                        df_removidos_display,
                        use_container_width=True,
                        height=min(400, len(df_removidos_display) * 35 + 38)
                    )
                    
                    # Op√ß√£o de download
                    st.markdown("---")
                    csv_removidos = df_removidos_display.to_csv(index=False)
                    st.download_button(
                        label="üì• Baixar registros removidos (CSV)",
                        data=csv_removidos,
                        file_name=f"registros_removidos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        help="Baixe um arquivo com todos os registros que foram removidos"
                    )
                    
                    st.info("üí° **Dica:** Revise estes registros para corrigir os problemas no arquivo original se necess√°rio")
        
        # Estat√≠sticas b√°sicas
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìä Total de Registros", f"{len(df_input):,}")
        with col2:
            st.metric("üí∞ Valor Total", f"R$ {df_input['valor'].sum():,.2f}")
        with col3:
            st.metric("üë• Matr√≠culas √önicas", f"{df_input['matricula'].nunique():,}")
            
            # An√°lise de dados e alertas
            registros_vazios = df_input.isnull().all(axis=1).sum()
            duplicatas = len(df_input) - len(df_input.drop_duplicates())
            valores_zero = (df_input['valor'] == 0).sum()
            
            if registros_vazios > 0 or duplicatas > 0 or valores_zero > 0:
                st.warning("‚ö†Ô∏è **Problemas detectados nos dados:**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    if registros_vazios > 0:
                        st.error(f"üóëÔ∏è {registros_vazios} linhas completamente vazias")
                with col2:
                    if duplicatas > 0:
                        st.warning(f"ÔøΩ {duplicatas} registros duplicados")
                with col3:
                    if valores_zero > 0:
                        st.info(f"‚ö™ {valores_zero} registros com valor zero")
                
                # Op√ß√µes de limpeza
                st.subheader("üßπ Limpeza de Dados")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    remover_vazios = st.checkbox("Remover linhas vazias", value=True)
                with col2:
                    remover_duplicatas = st.checkbox("Remover duplicatas", value=True)
                with col3:
                    remover_zeros = st.checkbox("Remover valores zero", value=False)
                
                if st.button("üßπ Aplicar Limpeza", type="secondary"):
                    df_original = df_input.copy()
                    
                    if remover_vazios:
                        df_input = df_input.dropna(how='all')
                        st.success(f"‚úÖ Removidas {len(df_original) - len(df_input)} linhas vazias")
                    
                    if remover_duplicatas:
                        df_antes = len(df_input)
                        df_input = df_input.drop_duplicates()
                        st.success(f"‚úÖ Removidas {df_antes - len(df_input)} duplicatas")
                    
                    if remover_zeros:
                        df_antes = len(df_input)
                        df_input = df_input[df_input['valor'] != 0]
                        st.success(f"‚úÖ Removidos {df_antes - len(df_input)} registros com valor zero")
                    
                    st.info(f"üìä Dataset limpo: {len(df_input)} registros restantes")
                    st.rerun()
            
            # Verificar se o dataset √© muito grande
            if len(df_input) > 10000:
                st.warning(f"‚ö†Ô∏è **Dataset muito grande:** {len(df_input)} registros")
                st.info("ÔøΩ **Recomenda√ß√µes:**")
                st.markdown("""
                - Considere processar em lotes menores
                - Verifique se h√° dados duplicados desnecess√°rios
                - O processamento pode ser mais lento
                """)
                
                processar_lotes = st.checkbox("Processar em lotes de 1000 registros", value=True)
                if processar_lotes:
                    st.session_state['processar_lotes'] = True
            
            # Preview dos dados
            with st.expander("üëÅÔ∏è Visualizar dados", expanded=False):
                st.dataframe(df_input.head(20), use_container_width=True)
                if len(df_input) > 20:
                    st.info(f"Mostrando as primeiras 20 linhas de {len(df_input)} registros")
            
            # ========================================
            # CONFIGURA√á√ÉO DOS CAMPOS
            # ========================================
            st.markdown("---")
            st.header("üìã Configura√ß√£o dos Dados")
            
            with st.form("config_form"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("üè∑Ô∏è Categoria")
                    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    categorias_file = os.path.join(base_dir, "categorias_nibo.xlsx")
                    
                    if os.path.exists(categorias_file):
                        df_cat = pd.read_excel(categorias_file)
                        # Usar as colunas corretas: 'Nome' e 'ID'
                        if 'Nome' in df_cat.columns:
                            categorias = df_cat['Nome'].tolist()
                            categoria_selecionada = st.selectbox("Categoria:", categorias)
                            if categoria_selecionada and 'ID' in df_cat.columns:
                                category_id = df_cat[df_cat['Nome'] == categoria_selecionada]['ID'].iloc[0]
                            else:
                                category_id = st.text_input("Category ID:")
                        else:
                            categoria_selecionada = st.text_input("Nome da categoria:")
                            category_id = st.text_input("Category ID:")
                    else:
                        categoria_selecionada = st.text_input("Nome da categoria:")
                        category_id = st.text_input("Category ID:")
                    
                    st.subheader("üìù Detalhes")
                    description = st.text_area("Descri√ß√£o:", value="Benef√≠cio processado automaticamente")
                    reference = st.text_input("Refer√™ncia:", value="PROC")
                
                with col2:
                    st.subheader("üìÖ Datas")
                    schedule_date = st.date_input("Agendamento:", value=datetime.now().date())
                    due_date = st.date_input("Vencimento:", value=datetime.now().date())
                    accrual_date = st.date_input("Compet√™ncia:", value=datetime.now().date())
                
                processar_clicked = st.form_submit_button("üìÑ Processar Dados", type="primary", use_container_width=True)
            
            # ========================================
            # PROCESSAMENTO
            # ========================================
            if processar_clicked:
                # Valida√ß√£o antes do processamento
                if len(df_input) == 0:
                    st.error("‚ùå Nenhum dado para processar ap√≥s a limpeza!")
                    st.stop()
                
                # Alerta para grandes volumes
                if len(df_input) > 50000:
                    st.error(f"‚ùå Dataset muito grande: {len(df_input)} registros")
                    st.warning("‚ö†Ô∏è Por favor, reduza o dataset para menos de 50.000 registros")
                    st.info("üí° Sugest√µes: remova duplicatas, valores zero ou processe em partes menores")
                    st.stop()
                elif len(df_input) > 10000:
                    st.warning(f"‚ö†Ô∏è Processando {len(df_input)} registros - isso pode demorar...")
                
                with st.spinner("üîÑ Processando dados..."):
                    # Carregar arquivos de refer√™ncia
                    df_stakeholders = None
                    df_cost_centers = None
                    
                    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    func_file = os.path.join(base_dir, "FUNC.xlsx")
                    centros_file = os.path.join(base_dir, "centros_de_custo.xlsx")
                    
                    # Progress bar para carregamento
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    status_text.text("üìÇ Carregando arquivo de funcion√°rios...")
                    progress_bar.progress(10)
                    
                    if os.path.exists(func_file):
                        df_stakeholders = pd.read_excel(func_file)
                        if 'matricula' in df_stakeholders.columns:
                            def _norm_matricula_func(x):
                                if pd.isna(x):
                                    return None
                                try:
                                    s = str(x).replace('.', '').replace(',', '').replace(' ', '')
                                    return int(s) if s.isdigit() else None
                                except:
                                    return None
                            df_stakeholders['matricula'] = df_stakeholders['matricula'].apply(_norm_matricula_func)
                    
                    status_text.text("üè¢ Carregando centros de custo...")
                    progress_bar.progress(20)
                    
                    if os.path.exists(centros_file):
                        df_cost_centers = pd.read_excel(centros_file)
                        df_cost_centers.columns = df_cost_centers.columns.str.lower()
                    
                    # Processar dados
                    status_text.text("‚öôÔ∏è Processando dados do arquivo...")
                    progress_bar.progress(30)
                    
                    df_resultado = df_input.copy()
                    
                    # Normalizar matr√≠cula
                    status_text.text("üî¢ Normalizando matr√≠culas...")
                    progress_bar.progress(40)
                    
                    def normalizar_matricula(x):
                        if pd.isna(x):
                            return ''
                        s = str(x).strip().replace('.', '').replace(',', '').replace(' ', '')
                        try:
                            if s == '':
                                return ''
                            if s.isdigit():
                                return int(s)
                            return int(float(s))
                        except:
                            return s
                    
                    df_resultado['matricula'] = df_resultado['matricula'].apply(normalizar_matricula)
                    df_resultado, ja_processados = verificar_ja_processado(df_resultado)
                    
                    # Gerar campos b√°sicos
                    status_text.text("üìù Gerando campos b√°sicos...")
                    progress_bar.progress(50)
                    
                    df_resultado['id'] = [gerar_id_unico() for _ in range(len(df_resultado))]
                    df_resultado['categoryid'] = category_id
                    df_resultado['value'] = df_resultado['valor'].apply(converter_valor_americano)
                    df_resultado['date'] = str(schedule_date)
                    df_resultado['vencimento'] = str(due_date)
                    df_resultado['data_competencia'] = str(accrual_date)
                    df_resultado['description'] = description
                    df_resultado['reference'] = reference
                    
                    # Buscar IDs - Otimizado para grandes volumes
                    status_text.text("üîç Buscando Stakeholder IDs...")
                    progress_bar.progress(60)
                    
                    # Usar merge para melhor performance em grandes datasets
                    if df_stakeholders is not None:
                        # Criar mapeamento de stakeholders
                        stakeholder_map = df_stakeholders.set_index('matricula')['Coluna2'].to_dict()
                        df_resultado['stakeholderid'] = df_resultado['matricula'].map(stakeholder_map)
                    else:
                        df_resultado['stakeholderid'] = None
                    
                    status_text.text("üè¢ Buscando Cost Center IDs...")
                    progress_bar.progress(70)
                    
                    if df_cost_centers is not None:
                        # Criar mapeamento de centros de custo
                        cost_center_map = df_cost_centers.set_index('id empresa')['id cliente'].to_dict()
                        df_resultado['costcenterid'] = df_resultado['idsetor'].map(cost_center_map)
                    else:
                        df_resultado['costcenterid'] = None
                    
                    # Validar resultados
                    status_text.text("‚úÖ Validando dados processados...")
                    progress_bar.progress(80)
                    
                    invalidos = df_resultado[
                        (df_resultado['stakeholderid'].isna()) | 
                        (df_resultado['costcenterid'].isna()) |
                        (df_resultado['value'] <= 0)
                    ]
                    
                    progress_bar.progress(90)
                    
                    # Limpar elementos de progresso
                    status_text.text("üéâ Processamento conclu√≠do!")
                    progress_bar.progress(100)
                    
                    # Aguardar um pouco e limpar
                    import time
                    time.sleep(1)
                    progress_bar.empty()
                    status_text.empty()
                    
                    if not invalidos.empty:
                        st.error(f"‚ùå {len(invalidos)} registros inv√°lidos encontrados de {len(df_resultado)} total!")
                        
                        # An√°lise detalhada dos problemas
                        problemas = []
                        stakeholders_faltando = invalidos['stakeholderid'].isna().sum()
                        centros_faltando = invalidos['costcenterid'].isna().sum() 
                        valores_invalidos = (invalidos['value'] <= 0).sum()
                        
                        if stakeholders_faltando > 0:
                            matriculas_problematicas = invalidos[invalidos['stakeholderid'].isna()]['matricula'].unique()
                            st.warning(f"üîç **{stakeholders_faltando} matr√≠culas n√£o encontradas no FUNC.xlsx**")
                            with st.expander(f"üìã Ver {len(matriculas_problematicas)} matr√≠culas problem√°ticas"):
                                st.write(matriculas_problematicas.tolist())
                                st.info("üí° **Solu√ß√£o:** Adicione estas matr√≠culas no arquivo FUNC.xlsx usando o Editor de Planilhas")
                        
                        if centros_faltando > 0:
                            setores_problematicos = invalidos[invalidos['costcenterid'].isna()]['idsetor'].unique()
                            st.warning(f"üè¢ **{centros_faltando} setores n√£o encontrados no centros_de_custo.xlsx**")
                            with st.expander(f"üìã Ver {len(setores_problematicos)} setores problem√°ticos"):
                                st.write("**IDs de Setor faltando:**")
                                for setor in setores_problematicos:
                                    st.write(f"‚Ä¢ **ID Empresa:** {setor}")
                                st.info("ÔøΩ **Solu√ß√£o:** Adicione estes setores no arquivo centros_de_custo.xlsx usando o Editor de Planilhas")
                                st.markdown("---")
                                st.markdown("**üîß Como adicionar no Editor:**")
                                st.markdown("""
                                1. V√° em "editor planilhas NOVO" no menu lateral
                                2. Selecione "centros_de_custo.xlsx"
                                3. Na aba "Adicionar Registro":
                                   - Preencha o "ID Empresa" com os valores acima
                                   - Preencha "Nome do Centro" 
                                   - Preencha "ID Cliente" (obtido da API NIBO)
                                4. Clique em "Adicionar Centro"
                                5. Volte aqui e reprocesse
                                """)
                        
                        if valores_invalidos > 0:
                            problemas.append(f"üí∞ {valores_invalidos} registros com valor zero ou negativo")
                        
                        with st.expander("üëÅÔ∏è Ver registros problem√°ticos (primeiros 100)"):
                            invalidos_display = invalidos[['matricula', 'idsetor', 'stakeholderid', 'costcenterid', 'value']].copy()
                            st.dataframe(invalidos_display.head(100), use_container_width=True)
                            if len(invalidos_display) > 100:
                                st.info(f"Mostrando os primeiros 100 de {len(invalidos_display)} registros problem√°ticos")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            continuar = st.checkbox("Continuar mesmo assim (processar apenas v√°lidos)", value=True)
                        with col2:
                            if st.button("üìä Baixar Registros Problem√°ticos"):
                                csv = invalidos_display.to_csv(index=False)
                                st.download_button(
                                    label="üìÑ Download CSV",
                                    data=csv,
                                    file_name=f"registros_problematicos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv"
                                )
                        
                        if continuar:
                            df_resultado = df_resultado[
                                (~df_resultado['stakeholderid'].isna()) & 
                                (~df_resultado['costcenterid'].isna()) &
                                (df_resultado['value'] > 0)
                            ]
                            st.success(f"‚úÖ Processando {len(df_resultado)} registros v√°lidos!")
                        else:
                            st.stop()
                    else:
                        st.success("‚úÖ Todos os dados processados com sucesso!")
                    
                    # Determinar registros para processar
                    if ja_processados > 0:
                        st.warning(f"‚ö†Ô∏è {ja_processados} registros j√° processados")
                        apenas_novos = st.checkbox("Processar apenas novos", value=True)
                        if apenas_novos:
                            registros_para_processar = df_resultado[df_resultado['jafoiprocessado'] == False]
                        else:
                            registros_para_processar = df_resultado
                            df_resultado['jafoiprocessado'] = False
                    else:
                        registros_para_processar = df_resultado
                    
                    st.info(f"üìä {len(registros_para_processar)} registros prontos")
                    
                    # Salvar resultado em session_state
                    st.session_state['df_processado'] = df_resultado
                    st.session_state['registros_novos'] = registros_para_processar
                    
                    # ========================================
                    # √ÅREA DE DOWNLOADS
                    # ========================================
                    st.markdown("---")
                    st.header("üì• Downloads - Dados Processados")
                    st.info("üí° **Importante:** Baixe o arquivo 'Dados Prontos para Postman' para usar na Etapa 2")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Excel completo
                        try:
                            output = BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                df_resultado.to_excel(writer, index=False)
                            st.download_button(
                                "üìä Excel Completo",
                                data=output.getvalue(),
                                file_name="dados_processados_completo.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                help="Todos os registros processados"
                            )
                        except Exception as e:
                            st.error(f"‚ùå Erro ao gerar Excel: {str(e)}")
                    
                    with col2:
                        # Apenas novos - ARQUIVO PRINCIPAL PARA ETAPA 2
                        if len(registros_para_processar) > 0:
                            output_novos = BytesIO()
                            
                            # Preparar dados para salvar
                            df_para_salvar = registros_para_processar.copy()
                            
                            # Renomear colunas para formato esperado pela Etapa 2
                            df_para_salvar = df_para_salvar.rename(columns={
                                'stakeholderid': 'stakeholderId',
                                'costcenterid': 'costCenterId',
                                'categoryid': 'categoryId',
                                'vencimento': 'Vencimento'
                            })
                            
                            with pd.ExcelWriter(output_novos, engine='openpyxl') as writer:
                                df_para_salvar.to_excel(writer, index=False)
                            
                            st.download_button(
                                "üìã Dados Prontos para Postman ‚≠ê",
                                data=output_novos.getvalue(),
                                file_name="dados_prontos_postman.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True,
                                type="primary",
                                help="üëâ Use este arquivo na Etapa 2 para gerar a cole√ß√£o Postman"
                            )
                            
                            st.success(f"‚úÖ {len(registros_para_processar)} registros prontos para Postman!")
                    
                    # Pr√≥ximos passos
                    st.markdown("---")
                    st.markdown("### üéØ Pr√≥ximos Passos")
                    st.info("""
                    1. ‚úÖ **Baixe** o arquivo "Dados Prontos para Postman"
                    2. üëâ **V√° para** "2Ô∏è‚É£ Gerar Cole√ß√£o Postman" no menu lateral
                    3. üì§ **Fa√ßa upload** do arquivo baixado
                    4. üöÄ **Gere** sua cole√ß√£o Postman
                    """)

    except Exception as e:
        st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")

else:
    # Instru√ß√µes quando n√£o h√° arquivo
    st.info("üìÅ Fa√ßa upload da planilha para come√ßar")
    
    with st.expander("üìã Instru√ß√µes de Uso", expanded=True):
        st.markdown("""
        ### üéØ Objetivo desta Etapa:
        Processar a planilha de benef√≠cios e buscar automaticamente os IDs necess√°rios.
        
        ### ÔøΩ Passo a Passo:
        1. **Prepare os arquivos de refer√™ncia** (j√° devem estar na pasta do projeto):
           - `FUNC.xlsx` - Matr√≠culas ‚Üí StakeholderIDs
           - `centros_de_custo.xlsx` - Setores ‚Üí CostCenterIDs
           - `categorias_nibo.xlsx` - Nomes ‚Üí CategoryIDs
        
        2. **Fa√ßa upload** da planilha modelo com os benef√≠cios
        
        3. **Configure**:
           - Categoria (ser√° aplicada a todos os registros)
           - Datas (agendamento, vencimento, compet√™ncia)
           - Descri√ß√£o e refer√™ncia
        
        4. **Clique em "Processar Dados"**
        
        5. **Baixe** o arquivo "Dados Prontos para Postman"
        
        6. **V√° para a Etapa 2** no menu lateral
        
        ### ‚úÖ O que ser√° feito automaticamente:
        - ‚úì Busca de StakeholderID usando matr√≠cula
        - ‚úì Busca de CostCenterID usando setor
        - ‚úì Valida√ß√£o de dados
        - ‚úì Normaliza√ß√£o de valores
        - ‚úì Controle de duplica√ß√£o
        """)

# Footer
st.markdown("---")
st.markdown("*üì§ Etapa 1 de 2 - Processamento de Dados*")